{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_ds = datasets.MNIST('data', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "test_ds = datasets.MNIST('data', train=False, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "class FlatMNIST(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.n = len(self.dataset)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset[idx]\n",
    "        return x.view(28*28), y\n",
    "\n",
    "    def __len__(self): return self.n\n",
    "    \n",
    "tr_ds = FlatMNIST(train_ds)\n",
    "ts_ds = FlatMNIST(test_ds)\n",
    "\n",
    "batch_size = 64\n",
    "#batch_size = 5 # for testing\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "if cuda:\n",
    "    train_loader = torch.utils.data.DataLoader(tr_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(ts_ds, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "else:\n",
    "    train_loader = torch.utils.data.DataLoader(tr_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(ts_ds, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilty Tree\n",
    "\n",
    "Used for intermediate calculations in the tree structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class prob_tree:\n",
    "    \"\"\"\n",
    "    Recursive class,  Designed for tree calculations \n",
    "    up and down the different branches\n",
    "    \"\"\"\n",
    "    def __init__(self, list_prob, node_prob=None, path_prob=None, lvl=1, max_depth=2):\n",
    "        \"\"\"\n",
    "        Initializes the tree. Takes in a list of probabilities \n",
    "        corresponding to trees:\n",
    "        \n",
    "        listprob = [ root, l, r, ll, lr, rl, rr .....]\n",
    "        lvl = assumes the current level (increases with recursion)\n",
    "        max_depth = end condition\n",
    "        path_prob = probability to REACH the current node, if \n",
    "            first node, the probability is 100%\n",
    "        node_prob = the probability of the current node to the next split\n",
    "        \"\"\"\n",
    "        \n",
    "        # if there is no path prob, then 100%\n",
    "        # must be passed \n",
    "        if path_prob is None:\n",
    "            self.path_prob = Variable(torch.ones(list_prob[0].shape))\n",
    "        else:\n",
    "            self.path_prob = path_prob\n",
    "            \n",
    "        # this is the probability within the current node\n",
    "        # if node probability isn't passed, pull from list\n",
    "        if node_prob is None:\n",
    "            self.prob = list_prob.pop(0)\n",
    "        else:\n",
    "            self.prob = node_prob\n",
    "        \n",
    "        self.lvl = lvl\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        \n",
    "        # since we are doing breath first searching\n",
    "        # will pass the node probabilities forward\n",
    "        if lvl < max_depth:\n",
    "            left_node_prob = list_prob.pop(0)\n",
    "            right_node_prob = list_prob.pop(0)\n",
    "            \n",
    "            self.left = prob_tree(list_prob, left_node_prob, self.path_prob*self.prob, self.lvl+1, self.max_depth)\n",
    "            self.right = prob_tree(list_prob, right_node_prob, self.path_prob*(1-self.prob), self.lvl+1, self.max_depth)\n",
    "        else:\n",
    "            self.left = None\n",
    "            self.right = None\n",
    "            \n",
    "    def get_leaf_path_probs(self):\n",
    "        \"\"\"\n",
    "        returns a list of path probabilities for only the leaf (recursive)\n",
    "        \"\"\"\n",
    "        if self.left is None:\n",
    "            return([self.path_prob*self.prob, self.path_prob*(1-self.prob) ])\n",
    "        else:\n",
    "            return(self.left.get_leaf_path_probs() + self.right.get_leaf_path_probs())\n",
    "            \n",
    "    def get_inner_path_probs(self):\n",
    "        \"\"\"\n",
    "        returns a list of path probabilities for only the inner nodes (recursive)\n",
    "        uses breath first algorithm\n",
    "        \"\"\"        \n",
    "        path_probs = []\n",
    "        nodes = [self]\n",
    "        while nodes:\n",
    "            current = nodes.pop(0)\n",
    "            path_probs.append((self.lvl-1,current.path_prob))\n",
    "            if current.left:\n",
    "                nodes.append(current.left)\n",
    "                nodes.append(current.right)\n",
    "        return(path_probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Neural Tree Class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NTree3(nn.Module):\n",
    "    def __init__(self, tree_depth=3, n_classes=10, ni=28*28, lmbda = 0.1, on_cuda=False, leaf_type ='const'):\n",
    "        super(NTree3,self).__init__()\n",
    "        self.n_leaves = 2**tree_depth\n",
    "        self.n_classes = n_classes\n",
    "        self.n_nodes = self.n_leaves -1\n",
    "        self.tree_depth = tree_depth\n",
    "        self.on_cuda = on_cuda\n",
    "        self.leaf_type = leaf_type\n",
    "        self.ptree = None\n",
    "        \n",
    "        # regularization\n",
    "        self.lmbda = lmbda\n",
    "\n",
    "\n",
    "        leaf_params = [torch.randn(self.n_classes) for i in range(self.n_leaves)]\n",
    "        beta_params = [torch.rand(1) for i in range(self.n_nodes)]\n",
    "                \n",
    "        if self.on_cuda==True:\n",
    "            beta_params = [beta_param.cuda() for beta_param in beta_params]\n",
    "            leaf_params = [leaf_param.cuda() for leaf_param in leaf_params]\n",
    "        \n",
    "        self.nodes =  nn.ModuleList([nn.Linear(ni, 1) for i in range(self.n_nodes)])\n",
    "        \n",
    "        if self.leaf_type == 'const':\n",
    "            self.leaves = nn.ParameterList([nn.Parameter(leaf_param) for leaf_param in leaf_params])\n",
    "        elif self.leaf_type == 'logreg':\n",
    "            self.leaves = nn.ModuleList([nn.Linear(ni, n_classes) for i in range(self.n_leaves)])\n",
    "                        \n",
    "        # inverse temperature filter\n",
    "        self.betas = nn.ParameterList([nn.Parameter(beta) for beta in beta_params])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        bz = x.size()[0]\n",
    "        sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # if we assume constant distribution in the leaft nodes\n",
    "        if self.leaf_type == 'const': \n",
    "            softmax = nn.Softmax(dim=0)\n",
    "        else: \n",
    "            softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        \n",
    "        # create distributions at each leaf - store for later\n",
    "        if self.leaf_type == 'const':\n",
    "            leaf_pcts = [softmax(leaf_param) for leaf_param in self.leaves]\n",
    "            leaf_dist = [pct.expand(bz, self.n_classes) for pct in leaf_pcts]\n",
    "            self.leaf_pcts = leaf_pcts\n",
    "        else:\n",
    "            leaf_dist = [softmax(leaf(x)) for leaf in self.leaves]\n",
    "        \n",
    "        \n",
    "        # probabilities of inner nodes\n",
    "        tmp = [self.nodes[i](x) for i in range(self.n_nodes)]\n",
    "        \n",
    "        p_x = [sigmoid(self.betas[i]*self.nodes[i](x)) for i in range(self.n_nodes)]\n",
    "        \n",
    "        tmp = [x for x in p_x]\n",
    "        pt = prob_tree(tmp, max_depth=self.tree_depth)\n",
    "        \n",
    "        path_prob = pt.get_leaf_path_probs()\n",
    "        \n",
    "        return leaf_dist, path_prob, p_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ConvTree(nn.Module):\n",
    "    def __init__(self, tree_depth=3, n_classes=10, ni=28*28, lmbda = 0.1, on_cuda=False, leaf_type ='const'):\n",
    "        super(ConvTree,self).__init__()\n",
    "        self.n_leaves = 2**tree_depth\n",
    "        self.n_classes = n_classes\n",
    "        self.n_nodes = self.n_leaves -1\n",
    "        self.tree_depth = tree_depth\n",
    "        self.on_cuda = on_cuda\n",
    "        self.leaf_type = leaf_type\n",
    "        self.ptree = None\n",
    "        \n",
    "        # regularization\n",
    "        self.lmbda = lmbda\n",
    "\n",
    "\n",
    "        leaf_params = [torch.randn(self.n_classes) for i in range(self.n_leaves)]\n",
    "        beta_params = [torch.rand(1) for i in range(self.n_nodes)]\n",
    "                \n",
    "        if self.on_cuda==True:\n",
    "            beta_params = [beta_param.cuda() for beta_param in beta_params]\n",
    "            leaf_params = [leaf_param.cuda() for leaf_param in leaf_params]\n",
    "        \n",
    "        self.conv_nodes = nn.ModuleList([nn.Conv2d(1,6,11) for i in range(self.n_nodes)])\n",
    "        self.nodes =  nn.ModuleList([nn.Linear(18*18*6, 1) for i in range(self.n_nodes)])\n",
    "        \n",
    "        if self.leaf_type == 'const':\n",
    "            self.leaves = nn.ParameterList([nn.Parameter(leaf_param) for leaf_param in leaf_params])\n",
    "        elif self.leaf_type == 'conv':\n",
    "            self.conv_leaves = nn.ModuleList([nn.Conv2d(1,1,11) for i in range(self.n_leaves)])\n",
    "            self.leaves = nn.ModuleList([nn.Linear(18*18, n_classes) for i in range(self.n_leaves)])\n",
    "        elif self.leaf_type == 'logreg':\n",
    "            self.leaves = nn.ModuleList([nn.Linear(ni, n_classes) for i in range(self.n_leaves)])\n",
    "\n",
    "        # inverse temperature filter\n",
    "        self.betas = nn.ParameterList([nn.Parameter(beta) for beta in beta_params])\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        bz = x.size()[0]\n",
    "        sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        # if we assume constant distribution in the leaft nodes\n",
    "        if self.leaf_type == 'const': \n",
    "            softmax = nn.Softmax(dim=0)\n",
    "        else: \n",
    "            softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "        \n",
    "        # create distributions at each leaf - store for later\n",
    "        if self.leaf_type == 'const':\n",
    "            leaf_pcts = [softmax(leaf_param) for leaf_param in self.leaves]\n",
    "            leaf_dist = [pct.expand(bz, self.n_classes) for pct in leaf_pcts]\n",
    "            self.leaf_pcts = leaf_pcts\n",
    "        elif self.leaf_type == 'conv':\n",
    "            conv_calc = [self.conv_leaves[i](x) for i in range(self.n_leaves)]\n",
    "            conv_calc2 = [conv_out.view(bz,-1) for conv_out in conv_calc]\n",
    "            leaf_dist = [softmax(leaf(conv_calc2[idx])) for idx, leaf in enumerate(self.leaves)]\n",
    "        elif self.leaf_type == 'logreg':\n",
    "            leaf_dist = [softmax(leaf(x.view(bz,-1))) for idx, leaf in enumerate(self.leaves)]\n",
    "        \n",
    "        # probabilities of inner nodes\n",
    "        conv_calc = [self.conv_nodes[i](x) for i in range(self.n_nodes)]\n",
    "        conv_calc2 = [conv_out.view(bz,-1) for conv_out in conv_calc]\n",
    "        p_x = [sigmoid(self.betas[i]*self.nodes[i](conv_calc2[i])) for i in range(self.n_nodes)]\n",
    "        \n",
    "        tmp = [x for x in p_x]\n",
    "        pt = prob_tree(tmp, max_depth=self.tree_depth)\n",
    "        \n",
    "        path_prob = pt.get_leaf_path_probs()\n",
    "        \n",
    "        return leaf_dist, path_prob, p_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bigot_leaf_loss(path_prob, leaf_dist, labels, on_cuda):\n",
    "    ymask = torch.FloatTensor(leaf_dist.size()).zero_()\n",
    "    if on_cuda:\n",
    "        ymask = ymask.cuda()    \n",
    "    ymask.scatter_(1, labels.data.view(-1,1), 1)\n",
    "    ymask = Variable(ymask)\n",
    "    Tk_log_Qk = (torch.log(leaf_dist) * ymask).sum(1)\n",
    "    PTQ = Tk_log_Qk[:,None]*path_prob\n",
    "    return torch.sum(PTQ)\n",
    "\n",
    "\n",
    "def penalty(p_x, max_depth, lmbda=0.1):\n",
    "    \n",
    "    tmp = [x for x in p_x]\n",
    "    ptree = prob_tree(tmp, max_depth=max_depth)\n",
    "    P_x = ptree.get_inner_path_probs()\n",
    "    \n",
    "    alphas = [(Px[0], torch.sum(torch.mul(Px[1],px))/torch.sum(Px[1])) for px, Px in zip(p_x, P_x)]\n",
    "    \n",
    "    def c1(alpha_i):\n",
    "        return 0.5*np.log(alpha_i) + 0.5*np.log(1-alpha_i)\n",
    "\n",
    "    C =  np.sum([-lmbda*2**-depth*c1(alp) for depth, alp in alphas])\n",
    "    return C\n",
    "\n",
    "def total_loss(path_probs, leaf_dists, p_x, labels, max_depth, lmbda=0.1,  on_cuda=False):\n",
    "    L_x = [bigot_leaf_loss(path_prob, leaf_dist, labels, on_cuda) for path_prob, leaf_dist in zip(path_probs, leaf_dists)]\n",
    "    C = penalty(p_x, max_depth, lmbda)\n",
    "    return(torch.log(-torch.sum(torch.stack(L_x)))+C)\n",
    "\n",
    "\n",
    "def which_node(path_prob, n_leaves, on_cuda=False):\n",
    "    node_id = torch.max(torch.stack(path_prob),dim=0)[1]    \n",
    "    nodes_onehot = torch.FloatTensor(path_prob[0].size()[0], n_leaves).zero_()\n",
    "    if on_cuda:\n",
    "        node_id = node_id.cuda()\n",
    "        nodes_onehot = nodes_onehot.cuda()\n",
    "    node_mask = nodes_onehot.scatter_(1, node_id.data,1)\n",
    "    return(node_id,node_mask)\n",
    "\n",
    "\n",
    "def which_class(path_prob, leaf_dist, on_cuda=False):\n",
    "    n_leaves = len(leaf_dist)\n",
    "    node_id, node_mask = which_node(path_prob, n_leaves, on_cuda)\n",
    "    max_class_per_node = torch.t(torch.max(torch.stack(leaf_dist),dim=2)[1])\n",
    "    pred_class = torch.sum(Variable(node_mask.long())*max_class_per_node,dim=1)\n",
    "    return(pred_class)\n",
    "\n",
    "\n",
    "def acc_calc(val_dl, model, on_cuda=False):\n",
    "    model.eval()\n",
    "    val_ = iter(val_dl)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    final_dist = 0\n",
    "\n",
    "    for i, batch in enumerate(val_dl):\n",
    "        data, labels = batch\n",
    "        if on_cuda:\n",
    "                data, labels = data.cuda(), labels.cuda()\n",
    "        data_var, labels_var = Variable(data), Variable(labels)        \n",
    "        leaf_dist, path_prob, p_nodes = model(data_var)\n",
    "        final_dist += which_node(path_prob, n_leaves = model.n_leaves, on_cuda=on_cuda)[1].sum(0)\n",
    "        \n",
    "        preds = which_class(path_prob, leaf_dist, on_cuda=on_cuda)\n",
    "        match = labels.eq(preds.data)\n",
    "        correct += match.sum()\n",
    "        total += match.size()[0]\n",
    "    return(correct/total, correct, total, final_dist) \n",
    "\n",
    "def plt_node_dist(leaf_pcts):\n",
    "    \"\"\"\n",
    "    .store_preds() must be run by calling .predict()\n",
    "    \"\"\"\n",
    "    n_leaves = len(leaf_pcts)\n",
    "    n_half = int(n_leaves/2) \n",
    "    fig, ax_array = plt.subplots(2, n_half, sharey=True)\n",
    "    fig.set_figwidth(12)\n",
    "    plt.setp(ax_array, xticks=[0,1,2,3,4,5,6,7,8,9])\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    for i, leaf_pct in enumerate(leaf_pcts):\n",
    "        pct_dict = {k:v for k,v in enumerate(leaf_pct.data.numpy())}\n",
    "        x = list(pct_dict.keys())\n",
    "        y = list(pct_dict.values())\n",
    "        if i < n_half:\n",
    "            ax_array[0,i].bar(x, height=y)\n",
    "            ax_array[0,i].set_title('Node %d' % i)\n",
    "        else:\n",
    "            ax_array[1,i-n_half].bar(x, height=y)\n",
    "            ax_array[1,i-n_half].set_title('Node %d' % i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_idx(batch_prob, master_tensor):\n",
    "    EMPTY_TENSOR = torch.zeros(1).nonzero()\n",
    "    local_prob = batch_prob.index_select(dim=0, index=Variable(master_tensor[:,0].long()))\n",
    "    left_mask = local_prob > 0.5\n",
    "    right_mask = local_prob <= 0.5\n",
    "    \n",
    "    l = left_mask.nonzero()\n",
    "    r = right_mask.nonzero()\n",
    "    \n",
    "    if len(l)>0:    \n",
    "        left_mask_idx = l[:,0].data    \n",
    "        left_idx = master_tensor.index_select(dim=0,index=left_mask_idx)\n",
    "    else:\n",
    "        left_idx = EMPTY_TENSOR\n",
    "        \n",
    "    if len(r)>0:\n",
    "        right_mask_idx = r[:,0].data\n",
    "        right_idx = master_tensor.index_select(dim=0,index=right_mask_idx)\n",
    "    else:\n",
    "        right_idx = EMPTY_TENSOR\n",
    "    return(left_idx, right_idx)\n",
    "\n",
    "\n",
    "def distribute_points(labels_var, p_x, max_depth):\n",
    "    EMPTY_TENSOR = torch.zeros(1).nonzero()\n",
    "    master_list = [(i,v) for i, v in enumerate(labels_var.data)]\n",
    "    master_tensor = torch.Tensor(master_list)\n",
    "\n",
    "    output = [master_tensor]\n",
    "    idx_queue = [master_tensor]\n",
    "    tmp = [a for a in p_x]\n",
    "    \n",
    "    iter_limit = 2**(max_depth)\n",
    "    counter = 1\n",
    "    while counter < iter_limit:\n",
    "        counter +=1\n",
    "        current_prob = tmp.pop(0)\n",
    "        current_labels = idx_queue.pop(0)\n",
    "\n",
    "        left_labels, right_labels = split_idx(current_prob, current_labels)\n",
    "        if len(left_labels) > 0:\n",
    "            output.append(left_labels)\n",
    "            idx_queue.append(left_labels)\n",
    "        else:\n",
    "            output.append(EMPTY_TENSOR)\n",
    "\n",
    "        if len(right_labels) > 0 :\n",
    "            output.append(right_labels)\n",
    "            idx_queue.append(right_labels)\n",
    "        else:\n",
    "            output.append(EMPTY_TENSOR)\n",
    "    return(output)\n",
    "\n",
    "def add_index(tensor, offset):\n",
    "    tensor[:,0] = tensor[:,0] + offset\n",
    "    return(tensor)\n",
    "\n",
    "def spread_test_distr(bz, model, test_loader):\n",
    "    max_depth = model.tree_depth\n",
    "    test_loader = iter(test_loader)\n",
    "    master_points_dist = {i:[] for i in range(2**(max_depth+1)-1)}\n",
    "    \n",
    "    for i, batch in enumerate(test_loader):\n",
    "        img_data, labels = batch\n",
    "        img_data_var, labels_var = Variable(img_data), Variable(labels)\n",
    "        leaf_dist, path_prob, p_x = model(img_data_var)\n",
    "        \n",
    "        # initialize\n",
    "        \n",
    "        points_dist = distribute_points(labels_var, p_x, max_depth)\n",
    "        for i, tensor in enumerate(points_dist):\n",
    "            master_points_dist[i].append(tensor)\n",
    "            \n",
    "            \n",
    "    \n",
    "    for k, v in master_points_dist.items():\n",
    "        master_points_dist[k] = torch.cat([add_index(tensor, j*bz) for j, tensor in enumerate(v) if len(tensor) > 0],dim=0)\n",
    "\n",
    "    return master_points_dist\n",
    "\n",
    "def plot_test_tree_spread(bz, model, test_loader):\n",
    "    max_depth = model.tree_depth\n",
    "    res = spread_test_distr(bz, model, test_loader)\n",
    "    tmp = [a for a in res.values()]\n",
    "\n",
    "\n",
    "    for i in range(0,max_depth+1):\n",
    "        fig, ax_array = plt.subplots(1, 2**i, sharey=True)\n",
    "        fig.set_size_inches(14,4)\n",
    "        for j in range(2**i):\n",
    "            tensor = tmp.pop(0)\n",
    "            ctr = dict(Counter(tensor[:,1]))\n",
    "            x = list(ctr.keys())\n",
    "            y = list(ctr.values())\n",
    "            if i == 0:\n",
    "                ax_array.bar(x, height=y)\n",
    "            else:\n",
    "                ax_array[j].bar(x, height=y)\n",
    "                \n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training for a log model at leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 0 , 00000/60000,  L: 5.247, A: 0.2314, dist [139, 943, 6624, 2294]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-19cc47a6a7d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mleaf_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-05208329a022>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-05208329a022>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mp_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbetas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "is_cuda = False\n",
    "lmbda = 0.1\n",
    "max_depth = 2\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "# flattened\n",
    "if is_cuda:\n",
    "    train_loader = torch.utils.data.DataLoader(tr_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(ts_ds, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "else:\n",
    "    train_loader = torch.utils.data.DataLoader(tr_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(ts_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \n",
    "model = NTree3(tree_depth=max_depth, n_classes=10, ni=28*28, lmbda = lmbda, on_cuda=is_cuda, leaf_type='logreg')\n",
    "\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "n_epochs = 5\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_dl = iter(train_loader)\n",
    "final_dist = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    train_dl = iter(train_loader)\n",
    "    \n",
    "    for i, batch in enumerate(train_dl):\n",
    "        data, labels = batch\n",
    "        bz = data.size()[0]\n",
    "        if is_cuda:\n",
    "            data = data.cuda()\n",
    "            labels = labels.cuda()\n",
    "        data_var, labels_var = Variable(data), Variable(labels)\n",
    "       \n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        leaf_dist, path_prob, p_x = model(data_var)\n",
    "        \n",
    "        loss = total_loss(path_prob, leaf_dist, p_x, labels_var, max_depth, lmbda, is_cuda)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%200 == 0:\n",
    "            acc, correct, total, dist = acc_calc(test_loader, model, on_cuda=is_cuda)\n",
    "            print('Ep: %d , %05d/60000,  L: %.03f, A: %.04f, dist %s' % (epoch, i*bz ,loss.data[0], acc, list(dist.long().cpu().numpy())))\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Nodes, Log Leafs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 0 , 00000/60000,  L: 5.530, A: 0.1611, dist [569, 822, 6428, 1764, 38, 229, 65, 85]\n",
      "Ep: 0 , 12800/60000,  L: 3.903, A: 0.9226, dist [1281, 766, 1398, 1962, 1417, 975, 1124, 1077]\n",
      "Ep: 0 , 25600/60000,  L: 3.007, A: 0.9346, dist [1330, 898, 1355, 1669, 1227, 1033, 935, 1553]\n",
      "Ep: 0 , 38400/60000,  L: 2.749, A: 0.9395, dist [1688, 1410, 891, 1322, 1168, 1161, 1342, 1018]\n",
      "Ep: 0 , 51200/60000,  L: 3.162, A: 0.9433, dist [851, 1019, 1665, 1228, 1385, 1214, 1300, 1338]\n",
      "Ep: 1 , 00000/60000,  L: 3.696, A: 0.9437, dist [1611, 1415, 1228, 983, 882, 888, 1415, 1578]\n",
      "Ep: 1 , 12800/60000,  L: 2.236, A: 0.9467, dist [1397, 1146, 1360, 969, 1433, 732, 1498, 1465]\n",
      "Ep: 1 , 25600/60000,  L: 3.324, A: 0.9486, dist [1706, 1370, 982, 1029, 932, 1008, 1415, 1558]\n",
      "Ep: 1 , 38400/60000,  L: 2.481, A: 0.9498, dist [1309, 1289, 1147, 787, 1302, 1290, 1352, 1524]\n",
      "Ep: 1 , 51200/60000,  L: 3.748, A: 0.9452, dist [1304, 1371, 1151, 1082, 1328, 1136, 1136, 1492]\n",
      "Ep: 2 , 00000/60000,  L: 2.975, A: 0.9478, dist [803, 1152, 1223, 922, 1414, 1760, 1311, 1415]\n",
      "Ep: 2 , 12800/60000,  L: 2.881, A: 0.9509, dist [1321, 1188, 1248, 1306, 1089, 1167, 1613, 1068]\n"
     ]
    }
   ],
   "source": [
    "is_cuda = False\n",
    "lmbda = 0.1\n",
    "max_depth = 3\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "\n",
    "# flattened\n",
    "if is_cuda:\n",
    "    train_loader = torch.utils.data.DataLoader(tr_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(ts_ds, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "else:\n",
    "    train_loader = torch.utils.data.DataLoader(tr_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(ts_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    \n",
    "# not flattened\n",
    "if is_cuda:\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, **kwargs)\n",
    "else:\n",
    "    train_loader = torch.utils.data.DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "    \n",
    "model = ConvTree(tree_depth=max_depth, n_classes=10, ni=28*28, lmbda = lmbda, on_cuda=is_cuda, leaf_type='logreg')\n",
    "\n",
    "if is_cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "n_epochs = 5\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_dl = iter(train_loader)\n",
    "final_dist = 0\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    running_loss = 0.0\n",
    "    train_dl = iter(train_loader)\n",
    "    \n",
    "    for i, batch in enumerate(train_dl):\n",
    "        data, labels = batch\n",
    "        bz = data.size()[0]\n",
    "        if is_cuda:\n",
    "            data = data.cuda()\n",
    "            labels = labels.cuda()\n",
    "        data_var, labels_var = Variable(data), Variable(labels)\n",
    "       \n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        leaf_dist, path_prob, p_x = model(data_var)\n",
    "        \n",
    "        loss = total_loss(path_prob, leaf_dist, p_x, labels_var, max_depth, lmbda, is_cuda)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%200 == 0:\n",
    "            acc, correct, total, dist = acc_calc(test_loader, model, on_cuda=is_cuda)\n",
    "            print('Ep: %d , %05d/60000,  L: %.03f, A: %.04f, dist %s' % (epoch, i*bz ,loss.data[0], acc, list(dist.long().cpu().numpy())))\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing constant distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt_node_dist(model.leaf_pcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz8AAAD8CAYAAABZwRrEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAELtJREFUeJzt3V2oXWedx/Hff3qsrzit9iiahEnF\noBZBLKFTFWQw4lgrxgsLlRkN0iE39V3Q6I0wc1NBfAMpBFunMuILVWjRolNqZZgLi6mKWqM01E5z\nbLVH1CqKaPE/F2eFHtvYJGcnZ5/d5/OBcNZ61rPPeg5sknyz1l6p7g4AAMBj3d/NewEAAACbQfwA\nAABDED8AAMAQxA8AADAE8QMAAAxB/AAAAEMQPwAAwBDEDwAAMATxAwAADGFp3gt4NOedd17v3Llz\n3ssAAAC2sNtvv/2X3b18onlbOn527tyZQ4cOzXsZAADAFlZV/3cy89z2BgAADEH8AAAAQxA/AADA\nEMQPAAAwBPEDAAAMQfwAAABDED8AAMAQxA8AADAE8QMAAAxhad4L4LFj54GvznsJm+Luqy6d9xIA\nANgAV34AAIAhiB8AAGAI4gcAABiC+AEAAIYgfgAAgCGIHwAAYAjiBwAAGIL4AQAAhiB+AACAIYgf\nAABgCOIHAAAYgvgBAACGIH4AAIAhiB8AAGAI4gcAABiC+AEAAIYgfgAAgCGIHwAAYAhL814AjGTn\nga/Oewmb4u6rLp33EgA2xO/T8Njmyg8AADCEE8ZPVV1bVfdX1Q/XjT2tqm6uqjunr+dO41VVn6iq\nI1X1/aq6cN1r9k3z76yqfWfmxwEAADi+k7ny859JXv2wsQNJbunuXUlumfaT5JIku6Zf+5NcnazF\nUpIPJvnHJBcl+eCxYAIAANgMJ/zMT3f/T1XtfNjw3iT/NG1fl+SbSd43jX+muzvJt6rqnKp61jT3\n5u7+VZJU1c1ZC6rPzfwTAI8Z7rUHYNH5s2xr2+hnfp7Z3fclyfT1GdP4tiRH181bmcb+1vgjVNX+\nqjpUVYdWV1c3uDwAAIC/drofeFDHGetHGX/kYPfB7t7d3buXl5dP6+IAAIBxbTR+fjHdzpbp6/3T\n+EqSHevmbU9y76OMAwAAbIqNxs+NSY49sW1fkhvWjb95eurbxUkemG6L+3qSV1XVudODDl41jQEA\nAGyKEz7woKo+l7UHFpxXVStZe2rbVUm+WFVXJLknyWXT9JuSvCbJkSR/SPKWJOnuX1XVfyT59jTv\n3489/GCR+AAbMG9+HwKAjTuZp7298W8c2nOcuZ3kyr/xfa5Ncu0prQ4AgC3FP8KwyE73Aw8AAAC2\nJPEDAAAM4YS3vQEAjx1uWQJG5soPAAAwBPEDAAAMQfwAAABDED8AAMAQxA8AADAE8QMAAAxB/AAA\nAEMQPwAAwBDEDwAAMATxAwAADEH8AAAAQ1ia9wIA4HTZeeCr817Cprj7qkvnvQSAheTKDwAAMATx\nAwAADEH8AAAAQxA/AADAEMQPAAAwBPEDAAAMQfwAAABDED8AAMAQxA8AADAE8QMAAAxB/AAAAEMQ\nPwAAwBBmip+qeldV3VFVP6yqz1XVE6rq/Kq6rarurKovVNXZ09zHT/tHpuM7T8cPAAAAcDI2HD9V\ntS3J25Ps7u4XJjkryeVJPpTko929K8mvk1wxveSKJL/u7ucm+eg0DwAAYFPMetvbUpInVtVSkicl\nuS/JK5JcPx2/Lsnrp+29036m43uqqmY8PwAAwEnZcPx098+SfDjJPVmLngeS3J7kN9394DRtJcm2\naXtbkqPTax+c5j99o+cHAAA4FbPc9nZu1q7mnJ/k2UmenOSS40ztYy95lGPrv+/+qjpUVYdWV1c3\nujwAAIC/Msttb69M8tPuXu3uPyf5cpKXJjlnug0uSbYnuXfaXkmyI0mm43+f5FcP/6bdfbC7d3f3\n7uXl5RmWBwAA8JBZ4ueeJBdX1ZOmz+7sSfKjJLcmecM0Z1+SG6btG6f9TMe/0d2PuPIDAABwJszy\nmZ/bsvbggu8k+cH0vQ4meV+Sd1fVkax9puea6SXXJHn6NP7uJAdmWDcAAMApWTrxlL+tuz+Y5IMP\nG74ryUXHmfvHJJfNcj4AAICNmvVR1wAAAAtB/AAAAEMQPwAAwBDEDwAAMATxAwAADEH8AAAAQxA/\nAADAEMQPAAAwBPEDAAAMQfwAAABDED8AAMAQxA8AADAE8QMAAAxB/AAAAEMQPwAAwBDEDwAAMATx\nAwAADEH8AAAAQxA/AADAEMQPAAAwBPEDAAAMQfwAAABDED8AAMAQxA8AADAE8QMAAAxB/AAAAEMQ\nPwAAwBDEDwAAMISZ4qeqzqmq66vqx1V1uKpeUlVPq6qbq+rO6eu509yqqk9U1ZGq+n5VXXh6fgQA\nAIATm/XKz8eTfK27n5/kRUkOJzmQ5Jbu3pXklmk/SS5Jsmv6tT/J1TOeGwAA4KRtOH6q6qlJXp7k\nmiTp7j9192+S7E1y3TTtuiSvn7b3JvlMr/lWknOq6lkbXjkAAMApmOXKz3OSrCb5dFV9t6o+VVVP\nTvLM7r4vSaavz5jmb0tydN3rV6axv1JV+6vqUFUdWl1dnWF5AAAAD5klfpaSXJjk6u5+cZLf56Fb\n3I6njjPWjxjoPtjdu7t79/Ly8gzLAwAAeMgs8bOSZKW7b5v2r89aDP3i2O1s09f7183fse7125Pc\nO8P5AQAATtqG46e7f57kaFU9bxrak+RHSW5Msm8a25fkhmn7xiRvnp76dnGSB47dHgcAAHCmLc34\n+rcl+WxVnZ3kriRvyVpQfbGqrkhyT5LLprk3JXlNkiNJ/jDNBQAA2BQzxU93fy/J7uMc2nOcuZ3k\nylnOBwAAsFGz/j8/AAAAC0H8AAAAQxA/AADAEMQPAAAwBPEDAAAMQfwAAABDED8AAMAQxA8AADAE\n8QMAAAxB/AAAAEMQPwAAwBDEDwAAMATxAwAADEH8AAAAQxA/AADAEMQPAAAwBPEDAAAMQfwAAABD\nED8AAMAQxA8AADAE8QMAAAxB/AAAAEMQPwAAwBDEDwAAMATxAwAADEH8AAAAQxA/AADAEGaOn6o6\nq6q+W1VfmfbPr6rbqurOqvpCVZ09jT9+2j8yHd8567kBAABO1um48vOOJIfX7X8oyUe7e1eSXye5\nYhq/Ismvu/u5ST46zQMAANgUM8VPVW1PcmmST037leQVSa6fplyX5PXT9t5pP9PxPdN8AACAM27W\nKz8fS/LeJH+Z9p+e5Dfd/eC0v5Jk27S9LcnRJJmOPzDNBwAAOOM2HD9V9dok93f37euHjzO1T+LY\n+u+7v6oOVdWh1dXVjS4PAADgr8xy5edlSV5XVXcn+XzWbnf7WJJzqmppmrM9yb3T9kqSHUkyHf/7\nJL96+Dft7oPdvbu7dy8vL8+wPAAAgIdsOH66+/3dvb27dya5PMk3uvtfktya5A3TtH1Jbpi2b5z2\nMx3/Rnc/4soPAADAmXAm/p+f9yV5d1Udydpneq6Zxq9J8vRp/N1JDpyBcwMAABzX0omnnFh3fzPJ\nN6ftu5JcdJw5f0xy2ek4HwAAwKk6E1d+AAAAthzxAwAADEH8AAAAQxA/AADAEMQPAAAwBPEDAAAM\nQfwAAABDED8AAMAQxA8AADAE8QMAAAxB/AAAAEMQPwAAwBDEDwAAMATxAwAADEH8AAAAQxA/AADA\nEMQPAAAwBPEDAAAMQfwAAABDED8AAMAQxA8AADAE8QMAAAxB/AAAAEMQPwAAwBDEDwAAMATxAwAA\nDEH8AAAAQxA/AADAEDYcP1W1o6purarDVXVHVb1jGn9aVd1cVXdOX8+dxquqPlFVR6rq+1V14en6\nIQAAAE5klis/DyZ5T3e/IMnFSa6sqguSHEhyS3fvSnLLtJ8klyTZNf3an+TqGc4NAABwSjYcP919\nX3d/Z9r+XZLDSbYl2ZvkumnadUleP23vTfKZXvOtJOdU1bM2vHIAAIBTcFo+81NVO5O8OMltSZ7Z\n3fcla4GU5BnTtG1Jjq572co09vDvtb+qDlXVodXV1dOxPAAAgNnjp6qekuRLSd7Z3b99tKnHGetH\nDHQf7O7d3b17eXl51uUBAAAkmTF+qupxWQufz3b3l6fhXxy7nW36ev80vpJkx7qXb09y7yznBwAA\nOFmzPO2tklyT5HB3f2TdoRuT7Ju29yW5Yd34m6envl2c5IFjt8cBAACcaUszvPZlSd6U5AdV9b1p\n7ANJrkryxaq6Isk9SS6bjt2U5DVJjiT5Q5K3zHBuAACAU7Lh+Onu/83xP8eTJHuOM7+TXLnR8wEA\nAMzitDztDQAAYKsTPwAAwBDEDwAAMATxAwAADEH8AAAAQxA/AADAEMQPAAAwBPEDAAAMQfwAAABD\nED8AAMAQxA8AADAE8QMAAAxB/AAAAEMQPwAAwBDEDwAAMATxAwAADEH8AAAAQxA/AADAEMQPAAAw\nBPEDAAAMQfwAAABDED8AAMAQxA8AADAE8QMAAAxB/AAAAEMQPwAAwBDEDwAAMIRNj5+qenVV/aSq\njlTVgc0+PwAAMKZNjZ+qOivJJ5NckuSCJG+sqgs2cw0AAMCYNvvKz0VJjnT3Xd39pySfT7J3k9cA\nAAAMaLPjZ1uSo+v2V6YxAACAM6q6e/NOVnVZkn/u7n+b9t+U5KLuftu6OfuT7J92n5fkJ5u2wK3p\nvCS/nPciWGjeQ8zKe4hZeQ8xK+8hTuQfunv5RJOWNmMl66wk2bFuf3uSe9dP6O6DSQ5u5qK2sqo6\n1N27570OFpf3ELPyHmJW3kPMynuI02Wzb3v7dpJdVXV+VZ2d5PIkN27yGgAAgAFt6pWf7n6wqt6a\n5OtJzkpybXffsZlrAAAAxrTZt72lu29KctNmn3eBuQWQWXkPMSvvIWblPcSsvIc4LTb1gQcAAADz\nstmf+QEAAJgL8bNFVdWrq+onVXWkqg7Mez0slqraUVW3VtXhqrqjqt4x7zWxmKrqrKr6blV9Zd5r\nYfFU1TlVdX1V/Xj6/egl814Ti6Wq3jX9OfbDqvpcVT1h3mtisYmfLaiqzkryySSXJLkgyRur6oL5\nrooF82CS93T3C5JcnORK7yE26B1JDs97ESysjyf5Wnc/P8mL4r3EKaiqbUnenmR3d78waw/Luny+\nq2LRiZ+t6aIkR7r7ru7+U5LPJ9k75zWxQLr7vu7+zrT9u6z9hWPbfFfFoqmq7UkuTfKpea+FxVNV\nT03y8iTXJEl3/6m7fzPfVbGAlpI8saqWkjwpD/v/IeFUiZ+taVuSo+v2V+IvrmxQVe1M8uIkt813\nJSygjyV5b5K/zHshLKTnJFlN8unp1slPVdWT570oFkd3/yzJh5Pck+S+JA9093/Pd1UsOvGzNdVx\nxjyWj1NWVU9J8qUk7+zu3857PSyOqnptkvu7+/Z5r4WFtZTkwiRXd/eLk/w+ic+wctKq6tys3fly\nfpJnJ3lyVf3rfFfFohM/W9NKkh3r9rfHZV5OUVU9Lmvh89nu/vK818PCeVmS11XV3Vm79fYVVfVf\n810SC2YlyUp3H7vqfH3WYghO1iuT/LS7V7v7z0m+nOSlc14TC078bE3fTrKrqs6vqrOz9uG+G+e8\nJhZIVVXW7rM/3N0fmfd6WDzd/f7u3t7dO7P2e9A3utu/uHLSuvvnSY5W1fOmoT1JfjTHJbF47kly\ncVU9afpzbU88NIMZLc17ATxSdz9YVW9N8vWsPdnk2u6+Y87LYrG8LMmbkvygqr43jX2gu2+a45qA\n8bwtyWenf8i7K8lb5rweFkh331ZV1yf5TtaeYvrdJAfnuyoWXXX7KAkAAPDY57Y3AABgCOIHAAAY\ngvgBAACGIH4AAIAhiB8AAGAI4gcAABiC+AEAAIYgfgAAgCH8P9Khbwt4YyyRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118459358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAz8AAAD8CAYAAABZwRrEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS2pzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11850aa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_test_tree_spread(bz, model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=784, out_features=1)\n",
       "  (1): Linear(in_features=784, out_features=1)\n",
       "  (2): Linear(in_features=784, out_features=1)\n",
       "  (3): Linear(in_features=784, out_features=1)\n",
       "  (4): Linear(in_features=784, out_features=1)\n",
       "  (5): Linear(in_features=784, out_features=1)\n",
       "  (6): Linear(in_features=784, out_features=1)\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=784, out_features=1)\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
