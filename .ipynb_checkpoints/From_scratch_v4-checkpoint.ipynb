{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fda18171870>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with PyTorch\n",
    "\n",
    "Setting up and trying:\n",
    "$$wx + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.randn((2*2,3))\n",
    "x = torch.randn((2*2,1))\n",
    "b = torch.randn((2*2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\n",
       " -2.9718  1.7070 -0.4305\n",
       " -2.2820  0.5237  0.0004\n",
       " -1.2039  3.5283  0.4434\n",
       "  0.5848  0.8407  0.5510\n",
       " [torch.FloatTensor of size 4x3], \n",
       "  0.3863\n",
       "  0.9124\n",
       " -0.8410\n",
       "  1.2282\n",
       " [torch.FloatTensor of size 4x1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-3.0141 -1.2067 -2.0324\n",
       "-0.6676  1.8924  1.4149\n",
       "-0.8656 -4.8455 -2.2510\n",
       " 0.2509  0.5651  0.2094\n",
       "[torch.FloatTensor of size 4x3]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w*x + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying the sigmoid and softmax functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.0468  0.2303  0.1158\n",
       " 0.3390  0.8690  0.8045\n",
       " 0.2962  0.0078  0.0953\n",
       " 0.5624  0.6376  0.5522\n",
       "[torch.FloatTensor of size 4x3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(x*w + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = nn.Linear(4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.4099 -0.8587  0.2726\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_var = Variable(x)\n",
    "fc(torch.t(x_var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "log_softmax() got an unexpected keyword argument 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-c6c1d6543b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: log_softmax() got an unexpected keyword argument 'dim'"
     ]
    }
   ],
   "source": [
    "F.log_softmax(fc(torch.t(x_var)), dim =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.3989  0.2976  0.5677\n",
       "[torch.FloatTensor of size 1x3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.sigmoid(fc(torch.t(x_var)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bz = 64\n",
    "input_dim = 28*28\n",
    "no_classes = 10\n",
    "max_depth = 2\n",
    "epochs = 4 \n",
    "lr = 0.01\n",
    "lmbda = 0.1\n",
    "momentum = 0.5\n",
    "seed = 1\n",
    "cuda = True\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Datasets (working with flattened ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_ds = datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))\n",
    "\n",
    "ts_ds = datasets.MNIST('./data', \n",
    "                   train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchvision.datasets.mnist.MNIST at 0x7fd9b880c5c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlatMNIST(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.n = len(self.dataset)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.dataset[idx]\n",
    "        return x.view(28*28), y\n",
    "\n",
    "    def __len__(self): return self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kwargs = {'num_workers': 1, 'pin_memory': True} \n",
    "flat_tr_ds = FlatMNIST(tr_ds)\n",
    "flat_ts_ds = FlatMNIST(ts_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loader\n",
    "train_loader = torch.utils.data.DataLoader(flat_tr_ds, batch_size=bz, shuffle=True)\n",
    "\n",
    "# test loader\n",
    "test_loader = torch.utils.data.DataLoader(flat_ts_ds, batch_size=bz, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the preview of the data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch,y = iter(train_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "          ...             â‹±             ...          \n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "-0.4242 -0.4242 -0.4242  ...  -0.4242 -0.4242 -0.4242\n",
       "[torch.FloatTensor of size 64x784]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "\n",
       "Columns 0 to 12 \n",
       "    1     5     3     3     3     9     3     9     7     4     3     1     9\n",
       "\n",
       "Columns 13 to 25 \n",
       "    8     5     2     1     2     9     4     4     3     6     5     6     1\n",
       "\n",
       "Columns 26 to 38 \n",
       "    8     1     8     4     8     7     3     9     5     1     3     8     2\n",
       "\n",
       "Columns 39 to 51 \n",
       "    5     1     9     5     3     0     3     9     8     3     9     0     3\n",
       "\n",
       "Columns 52 to 63 \n",
       "    7     2     8     9     4     8     6     0     7     5     1     3\n",
       "[torch.LongTensor of size 1x64]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.t(y.view(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 784]), torch.Size([3, 784]), 5, \n",
       "  1\n",
       "  5\n",
       "  3\n",
       " [torch.LongTensor of size 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_img = batch[1].view(1,-1)\n",
    "labels_one_img = y[1]\n",
    "\n",
    "three_img = batch[:3]\n",
    "labels_three_img = y[:3]\n",
    "\n",
    "one_img.shape, three_img.shape, labels_one_img, labels_three_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "\n",
    "- **`Q`** - classifier probabilities per class\n",
    "- **`path_prob`** - the chance of reaching each classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leaf Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeafNode:\n",
    "    def __init__(self, n_classes, input_dim):\n",
    "        self.is_leaf = True\n",
    "        self.n_classes = n_classes\n",
    "        self.input_dim = input_dim\n",
    "        self.fc = nn.Linear(input_dim, n_classes)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Calculates the probability distribution\n",
    "        through the FC layer and softmax\n",
    "        \"\"\"\n",
    "        self.Q = F.log_softmax(self.fc(x), dim =-1)\n",
    "        self.store_idx\n",
    "        return self.Q\n",
    "    \n",
    "    \n",
    "    def get_leaf_preds(self):\n",
    "        \"\"\"\n",
    "        returns the classes index tensor of batch passed\n",
    "        \"\"\"\n",
    "        return [torch.max(self.Q,-1)[1]]   \n",
    "    \n",
    "    \n",
    "    def store_idx(self):\n",
    "        \"\"\"\n",
    "        distribution by class is stored for later\n",
    "        \"\"\"\n",
    "        classes = {i:[] for i in range(self.n_classes)}    \n",
    "        min_log_scores = self.get_leaf_preds()\n",
    "        for idx, pred_class in enumerate(min_log_scores):\n",
    "            classes[pred_class.data[0]].append(idx)\n",
    "        self.class_dist = classes\n",
    "        return classes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.6841 -1.3732 -4.1771 -2.0015 -2.3998 -2.6090 -1.5152 -3.3764 -2.9696 -2.8413\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnode = LeafNode(n_classes = 10, input_dim = 28*28)\n",
    "lnode.forward(Variable(one_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the forward functino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.1914 -1.6561 -2.3321 -2.0608 -3.3195 -2.2332 -2.3915 -2.5436 -2.2356 -2.9461\n",
       "-2.6841 -1.3732 -4.1771 -2.0015 -2.3998 -2.6090 -1.5152 -3.3764 -2.9696 -2.8413\n",
       "-2.5553 -2.0972 -2.3819 -2.2844 -2.0122 -2.2101 -1.5853 -3.1362 -2.5815 -3.2714\n",
       "[torch.FloatTensor of size 3x10]"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnode.forward(Variable(three_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the index storing only in the leaf node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [], 1: [0], 2: [], 3: [], 4: [], 5: [], 6: [], 7: [], 8: [], 9: []}"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnode.store_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Variable containing:\n",
       "  1\n",
       "  1\n",
       "  6\n",
       " [torch.LongTensor of size 3]]"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lnode.get_leaf_preds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inner Node class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InnerNode:\n",
    "    def __init__(self, tree_depth, n_classes, input_dim, tree_lvl=1, lmbda = 0.1):\n",
    "        self.is_leaf = False\n",
    "        self.node_prob = None\n",
    "        self.lmbda = lmbda*2**-tree_lvl\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.tree_depth = tree_depth\n",
    "        self.tree_lvl = tree_lvl\n",
    "        self.input_dim = input_dim\n",
    "        self.fc = nn.Linear(input_dim, 1)\n",
    "        self.left, self.right = self.build_tree()\n",
    "        self.idx_left, self.idx_right = None, None\n",
    "        \n",
    "        \n",
    "    def build_tree(self):\n",
    "        if self.tree_lvl == self.tree_depth:\n",
    "            left = LeafNode(self.n_classes, self.input_dim)\n",
    "            right = LeafNode(self.n_classes, self.input_dim)\n",
    "        else:\n",
    "            left = InnerNode(self.tree_depth, self.n_classes, self.input_dim, self.tree_lvl+1, lmbda)\n",
    "            right = InnerNode(self.tree_depth, self.n_classes, self.input_dim, self.tree_lvl+1, lmbda)\n",
    "        return(left, right)\n",
    "            \n",
    "        \n",
    "    def store_idx(self):\n",
    "        bool_array = torch.Tensor(self.node_prob.data) > 0.5\n",
    "        flattened_bool = bool_array.numpy().reshape(-1)\n",
    "        \n",
    "        left_array = np.argwhere(flattened_bool == 1).reshape(-1)\n",
    "        right_array = np.argwhere(flattened_bool == 0).reshape(-1)\n",
    "\n",
    "        return left_array, right_array\n",
    "        \n",
    "    def get_leaf_preds(self):\n",
    "        all_leaf_preds = []\n",
    "        all_leaf_preds.extend(self.left.get_leaf_preds())\n",
    "        all_leaf_preds.extend(self.right.get_leaf_preds())\n",
    "        return all_leaf_preds\n",
    "        \n",
    "        \n",
    "    def forward(self, x, path_prob=None):\n",
    "        self.node_prob = F.sigmoid(self.fc(x))\n",
    "        \n",
    "        # for penalty\n",
    "        if path_prob is None:\n",
    "            self.path_prob = Variable(torch.ones(x.size()[0],1))\n",
    "        else:\n",
    "            self.path_prob = path_prob\n",
    "        \n",
    "        # calculate the alpha\n",
    "        self.alpha = torch.sum(self.path_prob*self.node_prob) / torch.sum(self.path_prob)\n",
    "        \n",
    "        # calculate the penalty C\n",
    "        self.penalty = -self.lmbda * (0.5*torch.log(self.alpha) + 0.5*torch.log(1-self.alpha))\n",
    "        self.penalty = self.penalty.data[0]\n",
    "        \n",
    "        # store IDs\n",
    "        self.idx_left, self.idx_right = self.store_idx()\n",
    "        \n",
    "        \n",
    "        # collect the Q and probs\n",
    "        prob_n_Q_list = []\n",
    "        \n",
    "        prob_left = self.node_prob\n",
    "        prob_right = 1-self.node_prob\n",
    "        \n",
    "        # leaf calculations\n",
    "        if self.left.is_leaf:\n",
    "            prob_n_Q_list.append([prob_left, self.left.forward(x)])\n",
    "            prob_n_Q_list.append([prob_right, self.right.forward(x)])\n",
    "        else:\n",
    "            prob_n_Q_list.extend([[prob_left*path_prob, Q] for path_prob, Q in self.left.forward(x, prob_left)])\n",
    "            prob_n_Q_list.extend([[prob_right*path_prob, Q] for path_prob, Q in self.right.forward(x, prob_right)])\n",
    "        return prob_n_Q_list\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the inner node class for a single image and for a set of 3 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Variable containing:\n",
       "   0.1690\n",
       "  [torch.FloatTensor of size 1x1], Variable containing:\n",
       "  -3.0264 -3.5390 -2.5160 -3.1451 -1.3241 -1.8215 -2.2681 -1.9325 -2.6390 -2.9747\n",
       "  [torch.FloatTensor of size 1x10]], [Variable containing:\n",
       "   0.1970\n",
       "  [torch.FloatTensor of size 1x1], Variable containing:\n",
       "  -2.9356 -2.4338 -1.8409 -2.1097 -3.5484 -3.3923 -1.8371 -2.2030 -2.6913 -1.7186\n",
       "  [torch.FloatTensor of size 1x10]], [Variable containing:\n",
       "   0.1957\n",
       "  [torch.FloatTensor of size 1x1], Variable containing:\n",
       "  -3.6697 -2.8965 -3.6453 -2.0817 -1.4956 -2.4257 -1.5871 -2.0120 -2.8828 -2.7852\n",
       "  [torch.FloatTensor of size 1x10]], [Variable containing:\n",
       "   0.4383\n",
       "  [torch.FloatTensor of size 1x1], Variable containing:\n",
       "  -1.5823 -2.4810 -3.2541 -1.9522 -2.5116 -4.1558 -1.7535 -2.5710 -2.0864 -2.8185\n",
       "  [torch.FloatTensor of size 1x10]]]"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inode = InnerNode(tree_depth=2, n_classes=10, input_dim=28*28)\n",
    "inode.forward(Variable(one_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Variable containing:\n",
       "   0.1395\n",
       "   0.1690\n",
       "   0.1793\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -2.9933 -2.9290 -1.3206 -2.4330 -2.0213 -2.0646 -2.8442 -2.1377 -2.8771 -2.9970\n",
       "  -3.0264 -3.5390 -2.5160 -3.1451 -1.3241 -1.8215 -2.2681 -1.9325 -2.6390 -2.9747\n",
       "  -1.5641 -3.4260 -2.7402 -2.1495 -2.0981 -2.3617 -2.1556 -2.2812 -2.6660 -2.6223\n",
       "  [torch.FloatTensor of size 3x10]], [Variable containing:\n",
       "   0.2890\n",
       "   0.1970\n",
       "   0.1674\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -2.5831 -1.9320 -2.2287 -2.2124 -2.6596 -2.6005 -1.8586 -2.4916 -2.5025 -2.3255\n",
       "  -2.9356 -2.4338 -1.8409 -2.1097 -3.5484 -3.3923 -1.8371 -2.2030 -2.6913 -1.7186\n",
       "  -3.3412 -1.4716 -1.7240 -1.9920 -2.8304 -3.3072 -2.5953 -3.0636 -2.5149 -2.1000\n",
       "  [torch.FloatTensor of size 3x10]], [Variable containing:\n",
       "   0.2799\n",
       "   0.1957\n",
       "   0.2650\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -2.8396 -2.6869 -3.6299 -2.1771 -1.9951 -2.1494 -1.7654 -1.7343 -2.5750 -2.8605\n",
       "  -3.6697 -2.8965 -3.6453 -2.0817 -1.4956 -2.4257 -1.5871 -2.0120 -2.8828 -2.7852\n",
       "  -3.2280 -2.6032 -2.9184 -2.7722 -2.0342 -1.9790 -1.2620 -1.8949 -3.6337 -3.1956\n",
       "  [torch.FloatTensor of size 3x10]], [Variable containing:\n",
       "   0.2917\n",
       "   0.4383\n",
       "   0.3882\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -1.9947 -2.6619 -1.9215 -2.4743 -2.1403 -2.9910 -1.9933 -3.1065 -2.2598 -2.2046\n",
       "  -1.5823 -2.4810 -3.2541 -1.9522 -2.5116 -4.1558 -1.7535 -2.5710 -2.0864 -2.8185\n",
       "  -2.6232 -2.6255 -2.3883 -1.6003 -1.3792 -3.2081 -2.5655 -2.7557 -2.4957 -3.0727\n",
       "  [torch.FloatTensor of size 3x10]]]"
      ]
     },
     "execution_count": 688,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q3 = inode.forward(Variable(three_img))\n",
    "Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03613061457872391, 0.01759452186524868, 0.01785583607852459)"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inode.penalty, inode.left.penalty, inode.right.penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty Equation for one node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.034657359028\n"
     ]
    }
   ],
   "source": [
    "path_prob = 0.5\n",
    "node_prob = 0.5\n",
    "lmbda = .1\n",
    "tree_lvl = 1\n",
    "\n",
    "alpha = (path_prob * node_prob)/path_prob\n",
    "alpha = 0.5\n",
    "print(alpha)\n",
    "\n",
    "print(-lmbda*2**-tree_lvl*(0.5*np.log(alpha) + 0.5*np.log(1-alpha)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_Qs = torch.stack([x[1] for x in Q3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([], dtype=int64))"
      ]
     },
     "execution_count": 592,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inode.store_idx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 5  8  0\n",
       " 4  2  1\n",
       " 8  2  3\n",
       " 9  9  1\n",
       "[torch.LongTensor of size 4x3]"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(inode.get_leaf_preds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NTree(nn.Module):\n",
    "    \n",
    "    def __init__(self, tree_depth=2, n_classes=10, input_dim = 28*28, lr=0.0001, lmbda = 0.01, penalty=True, cuda=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tree_depth = tree_depth\n",
    "        self.n_classes = n_classes\n",
    "        self.n_leaves = 2**tree_depth\n",
    "        self.input_dim = input_dim\n",
    "        self.lmbda = lmbda\n",
    "        self.prob_hist = []\n",
    "        self.penalty = penalty\n",
    "        self.cuda = cuda\n",
    "        self.pred_stats = {i: {j:0 for j in range(self.n_classes)} for i in range(self.n_leaves)}\n",
    "        \n",
    "        # initializing the tree class\n",
    "        self.root = InnerNode(tree_depth, n_classes, input_dim, tree_lvl=1, lmbda=lmbda)\n",
    "        \n",
    "        # getting the module list\n",
    "        self.mod_list = self.collect_params()\n",
    "        self.leaf_nodes = []\n",
    "        \n",
    "        # setting up the training objects\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        \n",
    "    def collect_params(self):\n",
    "        \"\"\"\n",
    "        Currently only collects nn layers. No parameters collected yet\n",
    "        \"\"\"\n",
    "        nodes = [self.root]\n",
    "        mod_list = nn.ModuleList()\n",
    "        \n",
    "        while nodes:\n",
    "            current = nodes.pop(0)\n",
    "            if current.is_leaf:\n",
    "                mod_list.append(current.fc)\n",
    "            else:\n",
    "                mod_list.append(current.fc)\n",
    "                nodes.append(current.left)\n",
    "                nodes.append(current.right)\n",
    "        return mod_list\n",
    "    \n",
    "    def collect_penalty(self):\n",
    "        nodes = [self.root]\n",
    "        total_penalty = 0\n",
    "        while nodes:\n",
    "            current = nodes.pop(0)\n",
    "            if not current.is_leaf:\n",
    "                total_penalty += current.penalty\n",
    "                nodes.append(current.left)\n",
    "                nodes.append(current.right)\n",
    "                \n",
    "        return(total_penalty)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.cuda:\n",
    "            x = x.cuda()\n",
    "        self.leaf_nodes = self.root.forward(x)\n",
    "        \n",
    "    def select_leaf(self):\n",
    "        \"\"\"\n",
    "        from all the leaf nodes, stacks up all the probabilities\n",
    "        then takes the max to find which class. Should only return\n",
    "        which of the depth^2 nodes has the largest probability to be \n",
    "        chosen\n",
    "        \"\"\"\n",
    "        stacked_probs = torch.stack([x[0] for x in self.leaf_nodes])\n",
    "        \n",
    "        # only returns class index\n",
    "        pred_leaf = torch.max(stacked_probs, dim=0)[1]\n",
    "        return(pred_leaf)\n",
    "    \n",
    "    \n",
    "    def store_node_probs(self):\n",
    "        self.prob_hist.append(self.root.node_prob)\n",
    "    \n",
    "    \n",
    "    def store_preds(self, masked_preds):\n",
    "        class_ , node_ = torch.max(masked_preds,dim=-1)\n",
    "        for c, n in zip(class_, node_):\n",
    "            self.pred_stats[int(n)][int(c)] +=1\n",
    "    \n",
    "    def predict(self, x):        \n",
    "        \"\"\"\n",
    "        pulls all predictions from all leaves\n",
    "        pulls all node predictions from path probabilities\n",
    "        \"\"\"\n",
    "        self.forward(x)        \n",
    "        all_leaf_preds = torch.stack(self.root.get_leaf_preds(),dim=1)\n",
    "        selected_leaves = self.select_leaf()\n",
    "\n",
    "        # making 1-hot encoding mask\n",
    "        leaf_mask = torch.FloatTensor(x.size()[0], self.n_leaves).zero_()\n",
    "        leaf_mask.scatter_(1, selected_leaves.data, 1)\n",
    "\n",
    "        # combiningthe mask\n",
    "        masked_preds = all_leaf_preds.float().data* leaf_mask\n",
    "        self.store_preds(masked_preds)\n",
    "        y_pred = (masked_preds).sum(1)\n",
    "        return(y_pred)\n",
    "    \n",
    "    def accuracy_counts(self, x, labels):\n",
    "        \"\"\"\n",
    "        assumes labels are tensors\n",
    "        \"\"\"\n",
    "        y_pred = self.predict(x)\n",
    "        bool_matrix = y_pred.eq(labels.data.float()).float()\n",
    "        return(torch.mean(bool_matrix), bool_matrix.size()[0], torch.sum(bool_matrix))\n",
    "    \n",
    "    \n",
    "    def labels2onehot(self, y, var = True):\n",
    "        \"\"\"\n",
    "        Turns y into 1-hot encoding tensor version\n",
    "        assume y submitted is a variable\n",
    "        \"\"\"\n",
    "        y_bz = y.size()[0]\n",
    "        \n",
    "        #initializes empty tensor zero\n",
    "        y_onehot = torch.FloatTensor(y_bz, self.n_classes).zero_()\n",
    "        \n",
    "        # fills the values with scatter\n",
    "        y_onehot.scatter_(1, y.data.view(-1,1),1)\n",
    "        \n",
    "        # then converts to variable\n",
    "        if var:\n",
    "            y_onehot = Variable(y_onehot)\n",
    "        if self.cuda:\n",
    "            y_onehot = y_onehot.cuda()\n",
    "        return(y_onehot)\n",
    "        \n",
    "        \n",
    "    def leaf_loss(self, leaf_Q, labels_onehot, leaf_path_prob):\n",
    "        \"\"\"\n",
    "        calculates loss per leaf node\n",
    "        \"\"\"\n",
    "        # only gets the probabilites of the correct values\n",
    "        logpy =(leaf_Q*labels_onehot).sum(1)\n",
    "\n",
    "        # adds a 1 dimension to the end\n",
    "        # then weights the path prob\n",
    "        log_weights = logpy.view(-1,1)*leaf_path_prob\n",
    "        return -log_weights.mean()\n",
    "    \n",
    "    \n",
    "    def tree_loss(self, labels):\n",
    "        \"\"\"\n",
    "        requires that forward has been called\n",
    "        \"\"\"\n",
    "        # pulls in labels\n",
    "        labels_onehot = self.labels2onehot(labels)\n",
    "        \n",
    "        # calcultes loss per leaf\n",
    "        loss_per_leaf = [self.leaf_loss(Q, labels_onehot, path_prob) for path_prob, Q in self.leaf_nodes]        \n",
    "        \n",
    "        # aggregate\n",
    "        total_loss = torch.sum(torch.stack(loss_per_leaf))\n",
    "        \n",
    "        if self.penalty:\n",
    "            penalty = self.collect_penalty()\n",
    "        else:\n",
    "            penalty = 0\n",
    "        \n",
    "        return(total_loss+penalty, penalty)\n",
    "    \n",
    "    \n",
    "    def train_tree(self, train_loader, epochs = 1):\n",
    "        self.train()\n",
    "        running_loss = 0\n",
    "        for j in range(epochs):\n",
    "            for i, data in enumerate(train_loader):\n",
    "                x, labels = data\n",
    "\n",
    "                x_var, labels_var = Variable(x), Variable(labels)\n",
    "                \n",
    "                if self.cuda:\n",
    "                    x_var = x_var.cuda()\n",
    "                    labels_var = labels_var.cuda()\n",
    "                    \n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                self.forward(x_var)\n",
    "                loss, penalty = self.tree_loss(labels_var)\n",
    "                loss.backward(retain_graph=True)\n",
    "                self.optimizer.step()\n",
    "\n",
    "                if i%200 == 0:\n",
    "                    batch_acc = self.accuracy_counts(x_var, labels_var)\n",
    "                    print('epoch: %d, batch: %d, loss %f, penalty: %f, acc: %s' % (j, i, loss.data[0], penalty, str(batch_acc)))\n",
    "                    #print(self.pred_stats)\n",
    "                    self.store_node_probs()\n",
    "                running_loss += loss.data[0]        \n",
    "            \n",
    "    def score_val(self, val_loader):\n",
    "        self.eval()\n",
    "        total_corr = 0\n",
    "        total_ct = 0\n",
    "        for i, data in enumerate(val_loader):\n",
    "            x, labels = data\n",
    "            \n",
    "            x_var, labels_var = Variable(x), Variable(labels)\n",
    "            \n",
    "            acc_pct, ct, corr_ct = self.accuracy_counts(x_var, labels_var)\n",
    "            total_ct += ct\n",
    "            total_corr += corr_ct\n",
    "            \n",
    "        return(total_corr/total_ct, total_ct, total_corr)\n",
    "            \n",
    "        \n",
    "    def plt_node_dist(self):\n",
    "        \"\"\"\n",
    "        .store_preds() must be run by calling .predict()\n",
    "        \"\"\"\n",
    "        fig, ax_array = plt.subplots(1, self.n_leaves, sharey=True)\n",
    "        fig.set_figwidth(12)\n",
    "        for i in range(self.n_leaves):\n",
    "            x = list(self.pred_stats[i].keys())\n",
    "            y = list(self.pred_stats[i].values())\n",
    "            ax_array[i].bar(x, height=y)\n",
    "            ax_array[i].set_title('Node %d' % i)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the neural tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ntree = NTree(tree_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0): Linear(in_features=784, out_features=1)\n",
       "  (1): Linear(in_features=784, out_features=1)\n",
       "  (2): Linear(in_features=784, out_features=1)\n",
       "  (3): Linear(in_features=784, out_features=10)\n",
       "  (4): Linear(in_features=784, out_features=10)\n",
       "  (5): Linear(in_features=784, out_features=10)\n",
       "  (6): Linear(in_features=784, out_features=10)\n",
       ")"
      ]
     },
     "execution_count": 1059,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntree.mod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Variable containing:\n",
       "   0.1994\n",
       "   0.2362\n",
       "   0.1554\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -3.2605 -3.8831 -2.6611 -2.6521 -2.1727 -2.0353 -1.8368 -1.8152 -1.7196 -2.9024\n",
       "  -2.0699 -3.0504 -1.8912 -2.6627 -2.2677 -2.7615 -2.7768 -1.6956 -2.2191 -2.4695\n",
       "  -2.0823 -3.9594 -1.9492 -2.6395 -2.8553 -2.4273 -2.5508 -1.6040 -1.9347 -2.6159\n",
       "  [torch.FloatTensor of size 3x10]], [Variable containing:\n",
       "   0.2586\n",
       "   0.3684\n",
       "   0.2992\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -1.8574 -1.7412 -2.4171 -2.8022 -2.1429 -2.7932 -1.9084 -3.4396 -2.4587 -2.6002\n",
       "  -1.4376 -2.5815 -2.6620 -2.4405 -3.1810 -2.2361 -1.5116 -2.9897 -2.8976 -2.8919\n",
       "  -1.4137 -2.4405 -2.2544 -2.6787 -2.7615 -2.9981 -1.3553 -3.0290 -3.0227 -3.5727\n",
       "  [torch.FloatTensor of size 3x10]], [Variable containing:\n",
       "   0.3493\n",
       "   0.1556\n",
       "   0.3207\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -2.2510 -1.5123 -2.1443 -2.0092 -2.5544 -2.7620 -3.2948 -3.0232 -2.9708 -1.9299\n",
       "  -2.3126 -1.5087 -2.5629 -2.9070 -2.2661 -2.3034 -3.5374 -2.2114 -2.4287 -2.1401\n",
       "  -2.6886 -2.0790 -2.7171 -2.5201 -2.7490 -2.4188 -2.4362 -2.5119 -2.0482 -1.5613\n",
       "  [torch.FloatTensor of size 3x10]], [Variable containing:\n",
       "   0.1927\n",
       "   0.2397\n",
       "   0.2248\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -1.6668 -2.4947 -1.9210 -2.3285 -2.1214 -2.1961 -3.4825 -2.0326 -4.5483 -2.5093\n",
       "  -2.3895 -2.0258 -2.7392 -2.8081 -3.2456 -3.4185 -1.7304 -1.2424 -3.3599 -2.5364\n",
       "  -1.8348 -2.7229 -1.9829 -2.5624 -3.4876 -1.7756 -2.6298 -1.8603 -3.2765 -2.3599\n",
       "  [torch.FloatTensor of size 3x10]]]"
      ]
     },
     "execution_count": 1060,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntree.forward(Variable(three_img))\n",
    "ntree.leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03891095542348921"
      ]
     },
     "execution_count": 1061,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntree.collect_penalty()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### all predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntree(Variable(three_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = ntree.predict(Variable(three_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ntree(Variable(batch))\n",
    "# ntree.predict(Variable(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 3, 0.0)"
      ]
     },
     "execution_count": 1065,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntree.accuracy_counts(Variable(three_img),Variable(labels_three_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#ntree.accuracy_counts(Variable(batch),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 1067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(10)\n",
    "b = torch.zeros(10)\n",
    "\n",
    "torch.mean(a.eq(b).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample loss calculation\n",
    "\n",
    "We store the path probabilities and the leaf distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[Variable containing:\n",
       "   0.1994\n",
       "   0.2362\n",
       "   0.1554\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -3.2605 -3.8831 -2.6611 -2.6521 -2.1727 -2.0353 -1.8368 -1.8152 -1.7196 -2.9024\n",
       "  -2.0699 -3.0504 -1.8912 -2.6627 -2.2677 -2.7615 -2.7768 -1.6956 -2.2191 -2.4695\n",
       "  -2.0823 -3.9594 -1.9492 -2.6395 -2.8553 -2.4273 -2.5508 -1.6040 -1.9347 -2.6159\n",
       "  [torch.FloatTensor of size 3x10]], [Variable containing:\n",
       "   0.2586\n",
       "   0.3684\n",
       "   0.2992\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -1.8574 -1.7412 -2.4171 -2.8022 -2.1429 -2.7932 -1.9084 -3.4396 -2.4587 -2.6002\n",
       "  -1.4376 -2.5815 -2.6620 -2.4405 -3.1810 -2.2361 -1.5116 -2.9897 -2.8976 -2.8919\n",
       "  -1.4137 -2.4405 -2.2544 -2.6787 -2.7615 -2.9981 -1.3553 -3.0290 -3.0227 -3.5727\n",
       "  [torch.FloatTensor of size 3x10]], [Variable containing:\n",
       "   0.3493\n",
       "   0.1556\n",
       "   0.3207\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -2.2510 -1.5123 -2.1443 -2.0092 -2.5544 -2.7620 -3.2948 -3.0232 -2.9708 -1.9299\n",
       "  -2.3126 -1.5087 -2.5629 -2.9070 -2.2661 -2.3034 -3.5374 -2.2114 -2.4287 -2.1401\n",
       "  -2.6886 -2.0790 -2.7171 -2.5201 -2.7490 -2.4188 -2.4362 -2.5119 -2.0482 -1.5613\n",
       "  [torch.FloatTensor of size 3x10]], [Variable containing:\n",
       "   0.1927\n",
       "   0.2397\n",
       "   0.2248\n",
       "  [torch.FloatTensor of size 3x1], Variable containing:\n",
       "  -1.6668 -2.4947 -1.9210 -2.3285 -2.1214 -2.1961 -3.4825 -2.0326 -4.5483 -2.5093\n",
       "  -2.3895 -2.0258 -2.7392 -2.8081 -3.2456 -3.4185 -1.7304 -1.2424 -3.3599 -2.5364\n",
       "  -1.8348 -2.7229 -1.9829 -2.5624 -3.4876 -1.7756 -2.6298 -1.8603 -3.2765 -2.3599\n",
       "  [torch.FloatTensor of size 3x10]]]"
      ]
     },
     "execution_count": 1068,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntree.leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "    0     0     0     0     1     0     0     0     0     0\n",
       "    0     0     0     0     0     0     0     0     1     0\n",
       "    0     0     0     0     0     0     0     1     0     0\n",
       "[torch.FloatTensor of size 3x10]"
      ]
     },
     "execution_count": 1069,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_onehot = ntree.labels2onehot(Variable(labels_three_img))\n",
    "labels_onehot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My version of the big function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Variable containing:\n",
      " 0.4022\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.8426\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.6919\n",
      "[torch.FloatTensor of size 1]\n",
      ", Variable containing:\n",
      " 0.5441\n",
      "[torch.FloatTensor of size 1]\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.4809\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 1070,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bigot_loss(Q, labels_onehot, path_prob):\n",
    "    # only gets the probabilites of the correct values\n",
    "    logpy =(Q*labels_onehot).sum(1)\n",
    "    \n",
    "    # adds a 1 dimension to the end\n",
    "    # then weights the path prob\n",
    "    log_weights = logpy.view(-1,1)*path_prob\n",
    "    return -log_weights.mean()\n",
    "    \n",
    "\n",
    "loss_per_leaf = [bigot_loss(Q, labels_onehot, path_prob) for path_prob, Q in ntree.leaf_nodes]\n",
    "print(loss_per_leaf)\n",
    "total_loss = torch.sum(torch.stack(loss_per_leaf))\n",
    "total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.4809\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 1071,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Bigot_loss(probs, labels, weights):\n",
    "    \"\"\" Loss for one bigot\n",
    "    \n",
    "    Arguments:\n",
    "    probs: tensor of log_probs for a mini-batch\n",
    "    labels: tensor of labels\n",
    "    weights: tensor of weights (per observation)\n",
    "    \n",
    "    Returns:\n",
    "    logpy: tensor of logloss (a logloss per observation)\n",
    "    \n",
    "    from here https://github.com/pytorch/pytorch/issues/563\n",
    "    \"\"\"\n",
    "    ymask = probs.data.new(probs.size()).zero_()\n",
    "    ymask.scatter_(1, labels.data.view(-1,1), 1)\n",
    "    ymask = Variable(ymask)\n",
    "    logpy = (probs * ymask).sum(1)\n",
    "    log_weights = logpy[:,None]*weights\n",
    "    return -log_weights.mean()\n",
    "    \n",
    "l = np.array([Bigot_loss(Q, Variable(labels_three_img), path_prob) for path_prob, Q in ntree.leaf_nodes])\n",
    "l.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  2.5198\n",
       " [torch.FloatTensor of size 1], 0.03891095542348921)"
      ]
     },
     "execution_count": 1072,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntree.tree_loss(Variable(labels_three_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we sum across trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = NTree(tree_depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# optimizer.zero_grad()\n",
    "# model(Variable(batch))\n",
    "# model.predict(Variable(batch))\n",
    "# loss, penalty = model.tree_loss(Variable(y))\n",
    "# print(loss)\n",
    "# loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# learning_rate = 0.0001\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# running_loss = 0\n",
    "# for i, data in enumerate(train_loader):\n",
    "#     x, labels = data\n",
    "    \n",
    "#     x_var, labels_var = Variable(x), Variable(labels)\n",
    "    \n",
    "#     optimizer.zero_grad()\n",
    "    \n",
    "#     model(x_var)\n",
    "#     loss, penalty = model.tree_loss(labels_var)\n",
    "#     loss.backward(retain_graph=True)\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     if i%200 == 0:\n",
    "#         print(i, loss.data)\n",
    "#     running_loss += loss.data[0]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data, test_labels = iter(test_loader).next()\n",
    "# test_data.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.accuracy_counts(Variable(test_data), Variable(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using all in built functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_model = NTree(tree_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: 2329, 1: 0, 2: 28, 3: 1, 4: 13, 5: 15, 6: 11, 7: 2, 8: 1, 9: 0}, 1: {0: 0, 1: 14, 2: 44, 3: 172, 4: 704, 5: 288, 6: 398, 7: 103, 8: 142, 9: 490}, 2: {0: 0, 1: 755, 2: 237, 3: 726, 4: 226, 5: 541, 6: 227, 7: 3955, 8: 627, 9: 1527}, 3: {0: 0, 1: 5, 2: 45, 3: 36, 4: 82, 5: 8, 6: 35, 7: 44, 8: 0, 9: 9}, 4: {0: 0, 1: 102, 2: 36, 3: 330, 4: 72, 5: 6, 6: 114, 7: 22, 8: 107, 9: 63}, 5: {0: 0, 1: 162, 2: 71, 3: 932, 4: 140, 5: 132, 6: 204, 7: 11, 8: 142, 9: 29}, 6: {0: 0, 1: 78, 2: 223, 3: 2194, 4: 2718, 5: 202, 6: 3615, 7: 83, 8: 638, 9: 11811}, 7: {0: 0, 1: 4035, 2: 2967, 3: 4549, 4: 798, 5: 1787, 6: 7002, 7: 97, 8: 266, 9: 422}}\n"
     ]
    }
   ],
   "source": [
    "tree_model.score_val(train_loader)\n",
    "print(tree_model.pred_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtYAAAEICAYAAAB7zLMEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b78c860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree_model.plt_node_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss 2.508301, penalty: 0.075967, acc: (0.125, 64, 8.0)\n",
      "epoch: 0, batch: 200, loss 0.964370, penalty: 0.137065, acc: (0.765625, 64, 49.0)\n",
      "epoch: 0, batch: 400, loss 0.801841, penalty: 0.173413, acc: (0.921875, 64, 59.0)\n",
      "epoch: 0, batch: 600, loss 0.564882, penalty: 0.186651, acc: (0.921875, 64, 59.0)\n",
      "epoch: 0, batch: 800, loss 0.629168, penalty: 0.199130, acc: (0.90625, 64, 58.0)\n",
      "epoch: 1, batch: 0, loss 0.667566, penalty: 0.220196, acc: (0.90625, 64, 58.0)\n",
      "epoch: 1, batch: 200, loss 0.604488, penalty: 0.227280, acc: (0.890625, 64, 57.0)\n",
      "epoch: 1, batch: 400, loss 0.604594, penalty: 0.234793, acc: (0.84375, 64, 54.0)\n",
      "epoch: 1, batch: 600, loss 0.496021, penalty: 0.236685, acc: (0.9375, 64, 60.0)\n",
      "epoch: 1, batch: 800, loss 0.582366, penalty: 0.232637, acc: (0.828125, 64, 53.0)\n"
     ]
    }
   ],
   "source": [
    "tree_model.train_tree(train_loader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: {0: 2381, 1: 0, 2: 29, 3: 1, 4: 13, 5: 15, 6: 11, 7: 2, 8: 1, 9: 0}, 1: {0: 0, 1: 14, 2: 44, 3: 172, 4: 706, 5: 289, 6: 398, 7: 103, 8: 144, 9: 490}, 2: {0: 0, 1: 756, 2: 237, 3: 726, 4: 226, 5: 541, 6: 227, 7: 3962, 8: 627, 9: 1528}, 3: {0: 0, 1: 5, 2: 45, 3: 36, 4: 82, 5: 8, 6: 35, 7: 44, 8: 0, 9: 9}, 4: {0: 0, 1: 102, 2: 36, 3: 330, 4: 72, 5: 6, 6: 114, 7: 22, 8: 107, 9: 63}, 5: {0: 0, 1: 163, 2: 71, 3: 933, 4: 140, 5: 132, 6: 204, 7: 11, 8: 142, 9: 29}, 6: {0: 0, 1: 78, 2: 223, 3: 2200, 4: 2718, 5: 202, 6: 3617, 7: 83, 8: 638, 9: 11821}, 7: {0: 0, 1: 4124, 2: 3025, 3: 4620, 4: 854, 5: 1825, 6: 7066, 7: 155, 8: 318, 9: 489}}\n"
     ]
    }
   ],
   "source": [
    "print(tree_model.pred_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtYAAAEICAYAAAB7zLMEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ac81d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree_model.plt_node_dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, batch: 0, loss 2.378673, penalty: 0.003467, acc: (0.140625, 64, 9.0)\n",
      "epoch: 0, batch: 200, loss 1.055469, penalty: 0.009057, acc: (0.703125, 64, 45.0)\n",
      "epoch: 0, batch: 400, loss 0.579131, penalty: 0.013214, acc: (0.90625, 64, 58.0)\n",
      "epoch: 0, batch: 600, loss 0.568567, penalty: 0.015381, acc: (0.859375, 64, 55.0)\n",
      "epoch: 0, batch: 800, loss 0.417274, penalty: 0.016982, acc: (0.875, 64, 56.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8872, 10000, 8872.0)"
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model = NTree(tree_depth=1)\n",
    "tree_model.train_tree(train_loader)\n",
    "tree_model.score_val(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {0: 1049,\n",
       "  1: 1225,\n",
       "  2: 1020,\n",
       "  3: 1030,\n",
       "  4: 1041,\n",
       "  5: 881,\n",
       "  6: 992,\n",
       "  7: 1007,\n",
       "  8: 993,\n",
       "  9: 1036},\n",
       " 1: {0: 0, 1: 5, 2: 2, 3: 4, 4: 1, 5: 7, 6: 9, 7: 14, 8: 4, 9: 0}}"
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.pred_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.9990\n",
       " 0.9950\n",
       " 0.9998\n",
       " 1.0000\n",
       " 0.9995\n",
       " 0.9996\n",
       " 0.9990\n",
       " 0.9991\n",
       " 0.9997\n",
       " 0.9948\n",
       " 0.9999\n",
       " 0.9991\n",
       " 0.9914\n",
       " 0.9999\n",
       " 0.9993\n",
       " 0.9979\n",
       "[torch.FloatTensor of size 16x1]"
      ]
     },
     "execution_count": 927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_model.root.node_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
